{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-f597cd46f62c>:65: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_tr, y_tr)\n",
      "C:\\Users\\youngjoo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "<ipython-input-6-f597cd46f62c>:65: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_tr, y_tr)\n",
      "C:\\Users\\youngjoo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "<ipython-input-6-f597cd46f62c>:65: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_tr, y_tr)\n",
      "C:\\Users\\youngjoo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "<ipython-input-6-f597cd46f62c>:65: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_tr, y_tr)\n",
      "C:\\Users\\youngjoo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "<ipython-input-6-f597cd46f62c>:65: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_tr, y_tr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선형회귀 Training set score: 0.816\n",
      "선형회귀 Validation set score: 0.787\n",
      "선형회귀 Validation_real set score: 0.733\n",
      "릿지회귀 Training set score: 0.792\n",
      "릿지회귀 Validation set score: 0.763\n",
      "릿지회귀 Validation_real set score: 0.737\n",
      "랜덤포레스트 Training set score: 0.944\n",
      "랜덤포레스트 Validation set score: 0.877\n",
      "랜덤포레스트 Validation_real set score: 0.873\n",
      "GBRT Training set score: 0.873\n",
      "GBRT Validation set score: 0.776\n",
      "GBRT Validation_real set score: 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youngjoo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Dec  4 16:53:36 2020\n",
    "\n",
    "@author: Song\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('KR_DATA.csv', encoding='cp949', index_col=0)\n",
    "#test = pd.read_csv('TEST.csv', encoding='cp949', index_col=0)\n",
    "\n",
    "myData = data[['likes', 'dislikes', 'comment_count', 'TAG_NUM', '기간']]\n",
    "target = data[['views']]\n",
    "\n",
    "#test_data = test[['likes', 'dislikes', 'comment_count', 'TAG_NUM', '기간']]\n",
    "#test_label = test[['views']]\n",
    "\n",
    "check = pd.concat([myData, target], axis=1)\n",
    "check.corr()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(myData, target, test_size=0.2, random_state=777)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "#test_data= scaler.transform(test_data)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_test = scaler.transform(y_test)\n",
    "#test_label= scaler.transform(test_label)\n",
    "\n",
    "\n",
    "# 3-1. LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "lr_train_avg, lr_val_avg,lr_valr_avg = 0, 0 ,0\n",
    "ridge_train_avg, ridge_val_avg, ridge_valr_avg = 0, 0, 0\n",
    "rf_train_avg, rf_val_avg, rf_valr_avg = 0, 0, 0\n",
    "gbrt_train_avg, gbrt_val_avg, gbrt_valr_avg = 0, 0, 0\n",
    "\n",
    "for _ in range(5):\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "    lr = LinearRegression().fit(X_tr, y_tr)\n",
    "    lr_train_avg += lr.score(X_tr, y_tr)\n",
    "    lr_val_avg += lr.score(X_val, y_val)\n",
    "    lr_valr_avg += lr.score(X_test, y_test)\n",
    "    \n",
    "    ridge = Ridge().fit(X_tr, y_tr)\n",
    "    ridge_train_avg += ridge.score(X_tr, y_tr)\n",
    "    ridge_val_avg += ridge.score(X_val, y_val)\n",
    "    ridge_valr_avg += ridge.score(X_test, y_test)\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "    rf.fit(X_tr, y_tr)\n",
    "    rf_train_avg += rf.score(X_tr, y_tr)\n",
    "    rf_val_avg += rf.score(X_val, y_val)\n",
    "    rf_valr_avg += rf.score(X_test, y_test)\n",
    "\n",
    "    gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "    gbrt.fit(X_tr, y_tr)\n",
    "    gbrt_train_avg += gbrt.score(X_tr, y_tr)\n",
    "    gbrt_val_avg += gbrt.score(X_val, y_val)\n",
    "    gbrt_valr_avg += gbrt.score(X_test, y_test)\n",
    "\n",
    "\n",
    "print(\"선형회귀 Training set score: {:.3f}\".format(lr_train_avg/5))\n",
    "print(\"선형회귀 Validation set score: {:.3f}\".format(lr_val_avg/5))\n",
    "print(\"선형회귀 Validation_real set score: {:.3f}\".format(lr_valr_avg/5))\n",
    "    \n",
    "print(\"릿지회귀 Training set score: {:.3f}\".format(ridge_train_avg/5))\n",
    "print(\"릿지회귀 Validation set score: {:.3f}\".format(ridge_val_avg/5))\n",
    "print(\"릿지회귀 Validation_real set score: {:.3f}\".format(ridge_valr_avg/5))\n",
    "    \n",
    "print(\"랜덤포레스트 Training set score: {:.3f}\".format(rf_train_avg/5))\n",
    "print(\"랜덤포레스트 Validation set score: {:.3f}\".format(rf_val_avg/5))\n",
    "print(\"랜덤포레스트 Validation_real set score: {:.3f}\".format(rf_valr_avg/5))\n",
    "\n",
    "print(\"GBRT Training set score: {:.3f}\".format(gbrt_train_avg/5))\n",
    "print(\"GBRT Validation set score: {:.3f}\".format(gbrt_val_avg/5))\n",
    "print(\"GBRT Validation_real set score: {:.3f}\".format(gbrt_valr_avg/5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-35016c540144>:61: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_tr, y_tr)\n",
      "C:\\Users\\youngjoo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "692/692 [==============================] - 2s 2ms/step - loss: 4.6192e-04\n",
      "Epoch 2/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 4.3189e-04\n",
      "Epoch 3/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 4.1029e-04\n",
      "Epoch 4/100\n",
      "692/692 [==============================] - 1s 1ms/step - loss: 3.9183e-04\n",
      "Epoch 5/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 3.7524e-04\n",
      "Epoch 6/100\n",
      "692/692 [==============================] - 1s 1ms/step - loss: 3.6065e-04\n",
      "Epoch 7/100\n",
      "692/692 [==============================] - 1s 1ms/step - loss: 3.4764e-04\n",
      "Epoch 8/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 3.3571e-04\n",
      "Epoch 9/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 3.2469e-04\n",
      "Epoch 10/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 3.1414e-04\n",
      "Epoch 11/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 3.0422e-04\n",
      "Epoch 12/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.9470e-04\n",
      "Epoch 13/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.8580e-04\n",
      "Epoch 14/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.7740e-04\n",
      "Epoch 15/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.6950e-04\n",
      "Epoch 16/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.6195e-04\n",
      "Epoch 17/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.5497e-04\n",
      "Epoch 18/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.4813e-04\n",
      "Epoch 19/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.4176e-04\n",
      "Epoch 20/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.3559e-04\n",
      "Epoch 21/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.2981e-04\n",
      "Epoch 22/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.2429e-04\n",
      "Epoch 23/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.1900e-04\n",
      "Epoch 24/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.1400e-04\n",
      "Epoch 25/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.0917e-04\n",
      "Epoch 26/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.0466e-04\n",
      "Epoch 27/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.0026e-04\n",
      "Epoch 28/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.9622e-04\n",
      "Epoch 29/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.9230e-04\n",
      "Epoch 30/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.8852e-04\n",
      "Epoch 31/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.8497e-04\n",
      "Epoch 32/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.8154e-04\n",
      "Epoch 33/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.7831e-04\n",
      "Epoch 34/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.7526e-04\n",
      "Epoch 35/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.7233e-04\n",
      "Epoch 36/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.6956e-04\n",
      "Epoch 37/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.6684e-04\n",
      "Epoch 38/100\n",
      "692/692 [==============================] - 2s 2ms/step - loss: 1.6435e-04\n",
      "Epoch 39/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.6205e-04\n",
      "Epoch 40/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.5973e-04\n",
      "Epoch 41/100\n",
      "692/692 [==============================] - 2s 2ms/step - loss: 1.5753e-04\n",
      "Epoch 42/100\n",
      "692/692 [==============================] - 2s 2ms/step - loss: 1.5548e-04\n",
      "Epoch 43/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.5360e-04\n",
      "Epoch 44/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.5165e-04\n",
      "Epoch 45/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.4997e-04\n",
      "Epoch 46/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.4828e-04\n",
      "Epoch 47/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.4673e-04\n",
      "Epoch 48/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.4515e-04\n",
      "Epoch 49/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.4370e-04\n",
      "Epoch 50/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.4236e-04\n",
      "Epoch 51/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.4106e-04\n",
      "Epoch 52/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.3987e-04\n",
      "Epoch 53/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.3867e-04\n",
      "Epoch 54/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.3767e-04\n",
      "Epoch 55/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.3659e-04\n",
      "Epoch 56/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.3558e-04\n",
      "Epoch 57/100\n",
      "692/692 [==============================] - 2s 2ms/step - loss: 1.3465e-04\n",
      "Epoch 58/100\n",
      "692/692 [==============================] - 2s 2ms/step - loss: 1.3380e-04\n",
      "Epoch 59/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.3302e-04\n",
      "Epoch 60/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.3212e-04\n",
      "Epoch 61/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.3146e-04\n",
      "Epoch 62/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.3078e-04\n",
      "Epoch 63/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.3003e-04\n",
      "Epoch 64/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.2937e-04\n",
      "Epoch 65/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.2878e-04\n",
      "Epoch 66/100\n",
      "692/692 [==============================] - 2s 2ms/step - loss: 1.2824e-04\n",
      "Epoch 67/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.2770e-04\n",
      "Epoch 68/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.2715e-04\n",
      "Epoch 69/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.2661e-04\n",
      "Epoch 70/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.2615e-04\n",
      "Epoch 71/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.2567e-04\n",
      "Epoch 72/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.2527e-04\n",
      "Epoch 73/100\n",
      "692/692 [==============================] - 2s 2ms/step - loss: 1.2490e-04\n",
      "Epoch 74/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.2447e-04\n",
      "Epoch 75/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.2398e-04\n",
      "Epoch 76/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.2373e-04\n",
      "Epoch 77/100\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 1.2334e-04\n",
      "Epoch 78/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.2303e-04\n",
      "Epoch 79/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.2269e-04\n",
      "Epoch 80/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.2234e-04\n",
      "Epoch 81/100\n",
      "692/692 [==============================] - 2s 2ms/step - loss: 1.2208e-04\n",
      "Epoch 82/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.2179e-04\n",
      "Epoch 83/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.2147e-04\n",
      "Epoch 84/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.2126e-04\n",
      "Epoch 85/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.2099e-04\n",
      "Epoch 86/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.2067e-04\n",
      "Epoch 87/100\n",
      "692/692 [==============================] - 2s 2ms/step - loss: 1.2044e-04\n",
      "Epoch 88/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.2022e-04\n",
      "Epoch 89/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.1998e-04\n",
      "Epoch 90/100\n",
      "692/692 [==============================] - 3s 4ms/step - loss: 1.1980e-04\n",
      "Epoch 91/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.1954e-04\n",
      "Epoch 92/100\n",
      "692/692 [==============================] - 2s 4ms/step - loss: 1.1931e-04\n",
      "Epoch 93/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.1904e-04\n",
      "Epoch 94/100\n",
      "692/692 [==============================] - 3s 4ms/step - loss: 1.1888e-04\n",
      "Epoch 95/100\n",
      "692/692 [==============================] - 3s 4ms/step - loss: 1.1873e-04\n",
      "Epoch 96/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.1847e-04\n",
      "Epoch 97/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.1830e-04\n",
      "Epoch 98/100\n",
      "692/692 [==============================] - 3s 4ms/step - loss: 1.1811e-04\n",
      "Epoch 99/100\n",
      "692/692 [==============================] - 3s 4ms/step - loss: 1.1784e-04\n",
      "Epoch 100/100\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 1.1772e-04\n",
      "선형회귀 Training set score: 0.806\n",
      "선형회귀 Validation set score: 0.818\n",
      "선형회귀 Validation_real set score: 0.724\n",
      "릿지회귀 Training set score: 0.779\n",
      "릿지회귀 Validation set score: 0.818\n",
      "릿지회귀 Validation_real set score: 0.736\n",
      "랜덤포레스트 Training set score: 0.940\n",
      "랜덤포레스트 Validation set score: 0.940\n",
      "랜덤포레스트 Validation_real set score: 0.879\n",
      "GBRT Training set score: 0.857\n",
      "GBRT Validation set score: 0.885\n",
      "GBRT Validation_real set score: 0.795\n",
      "신경망 Training set score: 0.6939851411\n",
      "신경망 Validation set score: 0.6286464426\n",
      "신경망 Validation_real set score: 0.8643565240\n"
     ]
    }
   ],
   "source": [
    "#### 조회 수 예측 모델링 ####\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "data = pd.read_csv('KR_DATA.csv', encoding='cp949', index_col=0)\n",
    "myData = data[['likes', 'dislikes', 'comment_count', 'TAG_NUM', '기간']]\n",
    "target = data[['views']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "X_train, X_test, y_train, y_test = train_test_split(myData, target, test_size=0.2, random_state=777)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_test = scaler.transform(y_test)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SSE =  K.sum(K.square( y_true - y_pred ))\n",
    "    SSR = K.sum(K.square( y_pred - np.mean(y_true) ) )\n",
    "    SST = K.sum(K.square( y_true - np.mean(y_true) ) )\n",
    "    return  tf.cast(SSR, tf.float64) / tf.cast(SST, tf.float64)\n",
    "\n",
    "lr_train_avg, lr_val_avg,lr_valr_avg = 0, 0 ,0\n",
    "ridge_train_avg, ridge_val_avg, ridge_valr_avg = 0, 0, 0\n",
    "rf_train_avg, rf_val_avg, rf_valr_avg = 0, 0, 0\n",
    "gbrt_train_avg, gbrt_val_avg, gbrt_valr_avg = 0, 0, 0\n",
    "deep_train_avg, deep_val_avg ,deep_valr_avg= 0, 0,0\n",
    "\n",
    "\n",
    "k = 1\n",
    "for _ in range(k):\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "    lr = LinearRegression().fit(X_tr, y_tr)\n",
    "    #results = lr.predict(X_val)\n",
    "    lr_train_avg += lr.score(X_tr, y_tr)\n",
    "    lr_val_avg += lr.score(X_val, y_val)\n",
    "    lr_valr_avg += lr.score(X_test, y_test)\n",
    "    \n",
    "    ridge = Ridge().fit(X_tr, y_tr)\n",
    "    #results = ridge.predict(X_val)\n",
    "    ridge_train_avg += ridge.score(X_tr, y_tr)\n",
    "    ridge_val_avg += ridge.score(X_val, y_val)\n",
    "    ridge_valr_avg += ridge.score(X_test, y_test)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "    rf.fit(X_tr, y_tr)\n",
    "    #results = rf.predict(X_val)\n",
    "    rf_train_avg += rf.score(X_tr, y_tr)\n",
    "    rf_val_avg += rf.score(X_val, y_val)\n",
    "    rf_valr_avg += rf.score(X_test, y_test)\n",
    "    \n",
    "    gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "    gbrt.fit(X_tr, y_tr)\n",
    "    #results = gbrt.predict(X_val)\n",
    "    gbrt_train_avg += gbrt.score(X_tr, y_tr)\n",
    "    gbrt_val_avg += gbrt.score(X_val, y_val)\n",
    "    gbrt_valr_avg += gbrt.score(X_test, y_test)\n",
    "    \n",
    "    leaky_relu = tf.nn.leaky_relu\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    # 이 부분에서 레이어를 줄이거나 늘려보기!\n",
    "    keras.layers.Dense(200, activation=leaky_relu, input_shape=(5,)),\n",
    "    keras.layers.Dense(200, activation=leaky_relu),\n",
    "    keras.layers.Dense(200, activation=leaky_relu),\n",
    "    keras.layers.Dense(200, activation=leaky_relu),\n",
    "    keras.layers.Dense(1, activation=leaky_relu),\n",
    "    ])\n",
    "    model.compile(loss =\"MSE\", optimizer=\"SGD\" )\n",
    "    history = model.fit(X_tr, y_tr, epochs=100, verbose=1)\n",
    "    # 이부분에서 에포크 수를 줄이거나 늘려보기\n",
    "    results = model.predict(X_val)\n",
    "    results2=model.predict(X_test)\n",
    "    \n",
    "    #print(coeff_determination(y_val, results))\n",
    "    \n",
    "    deep_train_avg += coeff_determination(y_tr, model.predict(X_tr))\n",
    "    deep_val_avg += coeff_determination(y_val, results)\n",
    "    deep_valr_avg += coeff_determination(y_test, results2)\n",
    "\n",
    "print(\"선형회귀 Training set score: {:.3f}\".format(lr_train_avg/k))\n",
    "print(\"선형회귀 Validation set score: {:.3f}\".format(lr_val_avg/k))\n",
    "print(\"선형회귀 Validation_real set score: {:.3f}\".format(lr_valr_avg/k))\n",
    "    \n",
    "print(\"릿지회귀 Training set score: {:.3f}\".format(ridge_train_avg/k))\n",
    "print(\"릿지회귀 Validation set score: {:.3f}\".format(ridge_val_avg/k))\n",
    "print(\"릿지회귀 Validation_real set score: {:.3f}\".format(ridge_valr_avg/k))\n",
    "    \n",
    "print(\"랜덤포레스트 Training set score: {:.3f}\".format(rf_train_avg/k))\n",
    "print(\"랜덤포레스트 Validation set score: {:.3f}\".format(rf_val_avg/k))\n",
    "print(\"랜덤포레스트 Validation_real set score: {:.3f}\".format(rf_valr_avg/k))\n",
    "\n",
    "print(\"GBRT Training set score: {:.3f}\".format(gbrt_train_avg/k))\n",
    "print(\"GBRT Validation set score: {:.3f}\".format(gbrt_val_avg/k))\n",
    "print(\"GBRT Validation_real set score: {:.3f}\".format(gbrt_valr_avg/k))\n",
    "\n",
    "print(\"신경망 Training set score: {:.10f}\".format(deep_train_avg/k))\n",
    "print(\"신경망 Validation set score: {:.10f}\".format(deep_val_avg/k))\n",
    "print(\"신경망 Validation_real set score: {:.10f}\".format(deep_valr_avg/k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
